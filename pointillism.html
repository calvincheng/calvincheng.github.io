<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Calvin Cheng</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    <link rel="icon" href="assets/svg/logo.svg">
    <link rel="stylesheet" href="style.css">
    <link href="https://fonts.googleapis.com/css2?family=EB+Garamond:wght@400;500;600&family=Nunito+Sans:wght@400;600;700&display=fallback" rel="stylesheet">
    <!--  For syntax highlighting -->
    <link rel="stylesheet" href="assets/styles/default.css">
    <script src="highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
  </head>
  <div class="nav-wrapper">
    <nav>
      <div class="logo">
        <a href="/">
          <!--<img src="assets/svg/logo.svg" alt="" height="50px">-->
          <svg class="logo-svg" height="50" width="50">
            <path d="M-401.27-840.63a4.22,4.22,0,0,0-.91-1,4.54,4.54,0,0,0-1.24-.69,4.35,4.35,0,0,0-1.44-.24,4.89,4.89,0,0,0-2.35.53,4.44,4.44,0,0,0-1.56,1.42,6.23,6.23,0,0,0-.87,2,10.08,10.08,0,0,0-.27,2.35,9.53,9.53,0,0,0,.27,2.27,6.1,6.1,0,0,0,.87,2,4.51,4.51,0,0,0,1.56,1.41,4.89,4.89,0,0,0,2.35.53,3.77,3.77,0,0,0,2.92-1.14,5.17,5.17,0,0,0,1.29-3h4a9.13,9.13,0,0,1-.81,3.13,7.28,7.28,0,0,1-1.72,2.38,7.15,7.15,0,0,1-2.49,1.5,9.13,9.13,0,0,1-3.15.52,9.4,9.4,0,0,1-3.84-.74,8.08,8.08,0,0,1-2.88-2,9.08,9.08,0,0,1-1.8-3,11.29,11.29,0,0,1-.62-3.77,11.62,11.62,0,0,1,.62-3.84,9.26,9.26,0,0,1,1.8-3.1,8.18,8.18,0,0,1,2.88-2.07,9.4,9.4,0,0,1,3.84-.75,9.51,9.51,0,0,1,2.9.44,8,8,0,0,1,2.45,1.28,7.09,7.09,0,0,1,1.78,2.09,7.29,7.29,0,0,1,.88,2.84h-3.95A3.41,3.41,0,0,0-401.27-840.63Z" transform="translate(414 846)"/>
            <path d="M-379.41-845.56v15.07h9.06v3.42h-13.14v-18.49Z" transform="translate(414 846)"/>
            <path d="M-407.73-796l-6-18.49h4.19l4.14,13h.05l4.19-13h4.22L-403.12-796Z" transform="translate(414 846)"/>
            <path d="M-382.32-814.49l7.75,12.4h.06v-12.4h3.82V-796h-4.08l-7.73-12.38h-.06V-796h-3.82v-18.49Z" transform="translate(414 846)"/>
            <path d="M-376.91-801.5l-32.69-5.74,5.77-32.51,32.68,5.73ZM-408.52-808l30.85,5.42,5.44-30.7-30.85-5.41Z" transform="translate(414 846)"/>
          </svg>
        </a>
      </div>
      <ul class="nav-links">
        <li>
          <a href="about">(about)</a>
        </li>
      </ul>
    </nav>
  </div>
  <body>
    <div class="article-wrapper fadein">
      <div class="article-heading">
        <h1>Braille and Pointillism</h1>
        <h2>Using Unicode braille characters to imitate pointillist art</h2>
      </div>
      <img class="article-cover" src="assets/img/moon.png">
      <div class="chapter-list-anchor">
        <div class="chapter-list-wrapper">
          <ul>
            <li class="chapter">
              <span class="chapter-current" onclick="scrollToId( 'subheading-1' )">
                Inspiration
              </span>
            </li>
            <li class="chapter"> 
              <span onclick="scrollToId( 'subheading-2' )">
                Canny edge detection
              </span>
            </li>
            <li class="chapter"> 
              <span onclick="scrollToId( 'subheading-3' )">
                Printing with braille
              </span>
            </li>
            <li class="chapter"> 
              <span onclick="scrollToId( 'subheading-4' )">
                Results
              </span>
            </li>
          </ul>
        </div>
      </div>
      <div class="article-info-wrapper">
        <div class="article-info">
          <h5>SKILLS</h5>
          <ul>
            <li>
              <span class="type-significant">Python</span>
              <span class="type-significant">NumPy</span>
              <span class="type-significant">SciPy</span>
            </li>
          </ul>
        </div>
        <div class="article-info">
          <h5>TOPICS</h5>
          <ul>
            <li>
              <span class="type-significant">Edge Detection</span>
              <span class="type-significant">Image Processing</span>
              <span class="type-significant">Unicode</span>
            </li>
          </ul>
        </div>
      </div>
      <div id="article-start" class="article-body">
        <!--
          • Description of terminal application (CLI)
          • Description of skills used (plotting, kernels, etc)
          • High level plan for each step (edge, then print)
        -->
        <p>
          The code for this project can be <a class="article-link"
          href="https://www.github.com/calvincheng/Pointillism">found
          on Github</a>.
        </p>
        <p>
          The program takes a given input image and renders it in a pointillist,
          line-drawn style. The points in the output are created using unicode
          braille characters, as inspired by
          the <a class="article-link"
                 href="https://github.com/asciimoo/drawille">drawille</a>
          package. The program may be run through a command line interface
          (CLI), where its parameters may be adjusted to tweak the output to the
          user's liking.
        </p>
        <p>
          To perform core image-processing functions such as individual pixel
          manipulation and kernel convolution, several standard Python
          libraries used for scientific computing such as <a class="article-link"
                               href="https://numpy.org">NumPy</a> and
                             <a class="article-link"
                               href="https://scipy.org">SciPy</a> are used.
          Overall, the program takes in an input image, identifies its edges
          using the Canny edge-detection algorithm, and prints points over where
          edges were found.
        </p>
        <h3 id="subheading-1">Inspiration</h3>
        <!--
          • m-i-s-o's art
          • High level plan for each step (edge, print, output)
        -->
        <p>
          I first discovered the Ukranian artist <a class="article-link"
            href="https://stanislavapinchuk.com/">Stanislava Pinchuk</a>
          (aka m-i-s-o) several years ago, where I was originally drawn by
          pictures of hand-poked tattoos she would give to her friends. The
          tattoos were done in a minimal, delicate style, often depicting
          cosmological entities such as constellations, stars and moons, or
          greenery such as wildflowers or branches. A few years later, she took
          her needle from skin to paper, plotting complex topographies through
          an intricate series of pin-holes.
        </p>
        <figure>
          <div style="width:70%" class="figure-wrapper">
            <img src="assets/img/fallout.jpg" alt="Stanislava
            Pinchuk – Fallout">
            <figcaption>Stanislava Pinchuk – Fallout</figcaption>
          </div>
        </figure>
        <p>
          Another indirect motivator for the project is based upon a work
          I saw at the Barbican Centre's exhibit <em>AI: More than Human</em>, 
          named <a class="article-link"
            href="http://annaridler.com/myriad-tulips">Myriad (Tulips)</a>. 
          Created by artist Anna Ridler, it consists of a neat grid of images of
          AI-generated tulips. The artwork made me think about the relationship
          between software and art – specifically, the extent to which software
          inspires or imitates art in the future.
        </p>
        <figure>
          <div style="width:100%" class="figure-wrapper">
            <img src="assets/img/tulips.jpeg" alt="Anna Ridler – Myriad (Tulips)">
            <figcaption>Anna Ridler – Myriad (Tulips)</figcaption>
          </div>
        </figure>
        <p>
          To see whether it's possible to imitate Pinchuk's artwork myself, I
          experimented with a multi-step process to generate images of a similar
          style. First, the program would take an imput image, and identify its
          edges with an edge detection algorithm. Then, it would take those
          detected edges and transform them into dotted lines. Finally, those
          dotted lines would then be printed upon a blank output image.
        </p>
        <h3 id="subheading-2">Canny edge detection</h3>
        <!--
            • Overview of each step in Canny
            • Overview pictures showing each step
        -->
        <p>
          The Canny edge detection algorithm was chosen due to its reliability
          and popularity. According to its <a class="article-link"
          href="https://en.wikipedia.org/wiki/Canny_edge_detector">Wikipedia
          article</a>, it may be broken down into five distinct steps:
        </p>
        <p>
          <ol>
            <li>Applying Gaussian blur to remove noise.</li>
            <li>Detect sudden changes in intensity.</li>
            <li>Thin potential edges.</li>
            <li>Threshold edges into strong, weak and zero categories.</li>
            <li>Perform hysteresis to track edges.</li>
          </ol>
        </p>
        <p>
          To apply Gaussian blur, a Gaussian kernel is convolved over the image.
          Although a convolution can be implemented manually using several
          for-loops, it is better (and more convenient) to utilise SciPy's
          <code class="inline">ndimage.convolve()</code> to take advantage 
          of its optimisations (e.g. using a FFT-based  method when it is faster
          to do so).
        </p>
        <pre><code class="python"><!--
     -->def gaussian_filter(img, sigma = 1):
<!-- -->    '''Applies Gaussian filter to image
<!-- -->    :img: Input image
<!-- -->    :sigma: Standard deviation – higher is blurrier
<!-- -->     '''
<!-- -->    kernel = generate_gaussian_kernel(sigma)
<!-- -->    result = ndimage.convolve(img, kernel, mode='nearest') 
<!-- -->    return result
<!-- --> 
<!-- --># Helper functions
<!-- -->def generate_gaussian_kernel(sigma = 1, n = 5):
<!-- -->    '''Generates a n-by-n zero-mean Gaussian kernel
<!-- -->    :sigma: Standard deviation used in the Gaussian function
<!-- -->    :n: Edge length
<!-- -->    '''
<!-- -->    return [[getGauss(x - n//2, y - n//2, 0, sigma) for x in range(n)] for y in range(n)]
<!-- --> 
<!-- -->def getGauss(x, y, mu, sigma):
<!-- -->    '''Generates Guassian function G(x, y)
<!-- -->    :mu: Average
<!-- -->    :sigma: Standard deviation
<!-- -->    '''
<!-- -->    coeff1 = 1 / math.sqrt(2 * math.pi * sigma**2)
<!-- -->    coeff2 = math.exp(-(x**2 + y**2) / (2 * sigma**2))
<!-- -->    return coeff1 * coeff2<!--
     --></code></pre>
        Running the Gaussian blur gives the resulting change:
        <figure>
          <div style="width:80%" class="figure-wrapper">
            <img class="sub-image" src="assets/img/step0.png">
            <img class="sub-image" src="assets/img/step1.png">
            <figcaption>Before (left) and after (right) performing Gaussian blur.</figcaption>
          </div>
        </figure>
        <p>
          The second step involves detecting sudden changes in intensity (i.e.
          an edge). This is performed via another kernel; in this case, the
          Sobel operator. Convolving the Sobel operator over the image in both
          horizontal (x) and vertical (y) directions provides the resulting
          images <code class="inline">G_x</code> and <code
          class="inline">G_y</code> where each point in the images represents an
          intensity gradient in the results' respective direction.
        </p>
        <figure>
          <div style="width:85%" class="figure-wrapper">
            <img src="assets/img/sobelKernels.png" alt="Sobel Kernels">
            <figcaption>The Sobel operators in both horizontal (x) and vertical (y) directions.</figcaption>
          </div>
        </figure>
        <p>
          The two resulting image gradients can then be combined to calculate
          the overall magnitude and direction via standard vector maths.
        </p>
        <pre><code class="python"><!--
     -->def sobel(img):
<!-- -->    '''Outputs sobel magnitude and direction (in degrees)
<!-- -->    :img: Input image
<!-- -->    '''
<!-- -->    SOBEL_X = np.array([[ 1,  0, -1],
<!-- -->                        [ 2,  0, -2],
<!-- -->                        [ 1,  0, -1]])
<!-- -->
<!-- -->    SOBEL_Y = np.array([[ 1,  2,  1],
<!-- -->                        [ 0,  0,  0],
<!-- -->                        [-1, -2, -1]])
<!-- -->
<!-- -->    G_x = ndimage.convolve(img, SOBEL_X, mode='nearest')
<!-- -->    G_y = ndimage.convolve(img, SOBEL_Y, mode='nearest')
<!-- -->
<!-- -->    G = np.sqrt(G_x**2 + G_y**2)
<!-- -->    theta = np.arctan2(G_y, G_x) * (180 / math.pi)
<!-- -->    return G, theta<!--
     --></code></pre>
        <p>
          Once again, SciPy is used to perform kernel convolutions. Applying the
          Sobel operator to our image and looking at its magnitude gives the
          below result.
        </p>
        <figure>
          <div style="width:40%" class="figure-wrapper">
            <img src="assets/img/step2.png" alt="Sobel operator applied to original image">
            <figcaption>The image's intensity gradient.</figcaption>
          </div>
        </figure>
        <p>
          The edges are now identified, but their thicknesses vary, as well as
          their magnitudes (some lines are brighter than others). By definition,
          edges should be a single pixel thin. Ideally, they should also be
          deterministic – a point within the image is either an edge or it
          isn't. These issues will be fixed in the remaining steps.
        </p>
        <h3 id="subheading-3">Printing with braille</h3>
        <p>
        </p>
        <h3 id="subheading-4">Results</h3>
      </div>
    </div>
    <script src="script.js"></script>
  </body>
</html>
